{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Builder Pattern\n",
    "\n",
    "The Builder Pattern is a creational design pattern that separates the construction of a complex object from its representations. This allows the same construction process to produce different representation of an object.\n",
    "\n",
    "## Use Case 1:\n",
    "\n",
    "In the context of an LLM system, the Builder Pattern can be used to:\n",
    "* Assemble configurations for LLM pipelines or requests dynamically.\n",
    "* Build prompts with multiple optional sections or formatting rules.\n",
    "* Construct large datasets or batch inputs for model inference.\n",
    "\n",
    "#### Python Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prompt:\n",
    "    def __init__(self):\n",
    "        self.sections = []\n",
    "\n",
    "    def add_section(self, section):\n",
    "        self.sections.append(section)\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"\\n\\n\".join(self.sections)\n",
    "\n",
    "# Builder Interface\n",
    "class PromptBuilder:\n",
    "    def __init__(self):\n",
    "        self.prompt = Prompt()\n",
    "\n",
    "    def add_user_input(self, user_input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def add_examples(self, examples):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def add_guidelines(self, guidelines):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_prompt(self):\n",
    "        return self.prompt\n",
    "\n",
    "# Concrete Builder\n",
    "class StandardPromptBuilder(PromptBuilder):\n",
    "    def add_user_input(self, user_input):\n",
    "        self.prompt.add_section(f\"User Input: {user_input}\")\n",
    "\n",
    "    def add_examples(self, examples):\n",
    "        examples_text = \"\\n\".join([f\"Example {i+1}: {ex}\" for i, ex in enumerate(examples)])\n",
    "        self.prompt.add_section(f\"Examples:\\n{examples_text}\")\n",
    "\n",
    "    def add_guidelines(self, guidelines):\n",
    "        self.prompt.add_section(f\"Guidelines: {guidelines}\")\n",
    "\n",
    "# Director\n",
    "class PromptDirector:\n",
    "    def __init__(self, builder):\n",
    "        self.builder = builder\n",
    "\n",
    "    def construct_prompt(self, user_input, examples=None, guidelines=None):\n",
    "        self.builder.add_user_input(user_input)\n",
    "        if examples:\n",
    "            self.builder.add_examples(examples)\n",
    "        if guidelines:\n",
    "            self.builder.add_guidelines(guidelines)\n",
    "        return self.builder.get_prompt()\n",
    "    \n",
    "builder = StandardPromptBuilder()\n",
    "director = PromptDirector(builder)\n",
    "\n",
    "prompt = director.construct_prompt(\n",
    "    user_input=\"What is the capital of France?\",\n",
    "    examples=[\"What is the largest planet?\", \"Explain photosynthesis.\"],\n",
    "    guidelines=\"Be concise and clear.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Input: What is the capital of France?\n",
      "\n",
      "Examples:\n",
      "Example 1: What is the largest planet?\n",
      "Example 2: Explain photosynthesis.\n",
      "\n",
      "Guidelines: Be concise and clear.\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case 2:\n",
    "\n",
    "You can use the Builder Pattern to dynamically construct LLM API request payloads with optional parameters.\n",
    "\n",
    "#### Python Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': 'Tell me a joke.', 'max_tokens': 50, 'temperature': 0.7, 'top_p': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# Product\n",
    "class LLMRequest:\n",
    "    def __init__(self):\n",
    "        self.parameters = {}\n",
    "\n",
    "    def set_parameter(self, key, value):\n",
    "        self.parameters[key] = value\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.parameters)\n",
    "\n",
    "# Builder Interface\n",
    "class LLMRequestBuilder:\n",
    "    def __init__(self):\n",
    "        self.request = LLMRequest()\n",
    "\n",
    "    def set_prompt(self, prompt):\n",
    "        self.request.set_parameter(\"prompt\", prompt)\n",
    "\n",
    "    def set_max_tokens(self, max_tokens):\n",
    "        self.request.set_parameter(\"max_tokens\", max_tokens)\n",
    "\n",
    "    def set_temperature(self, temperature):\n",
    "        self.request.set_parameter(\"temperature\", temperature)\n",
    "\n",
    "    def set_top_p(self, top_p):\n",
    "        self.request.set_parameter(\"top_p\", top_p)\n",
    "\n",
    "    def get_request(self):\n",
    "        return self.request\n",
    "\n",
    "# Director\n",
    "class LLMRequestDirector:\n",
    "    def __init__(self, builder):\n",
    "        self.builder = builder\n",
    "\n",
    "    def construct_request(self, prompt, max_tokens=None, temperature=None, top_p=None):\n",
    "        self.builder.set_prompt(prompt)\n",
    "        if max_tokens:\n",
    "            self.builder.set_max_tokens(max_tokens)\n",
    "        if temperature:\n",
    "            self.builder.set_temperature(temperature)\n",
    "        if top_p:\n",
    "            self.builder.set_top_p(top_p)\n",
    "        return self.builder.get_request()\n",
    "\n",
    "# Usage\n",
    "builder = LLMRequestBuilder()\n",
    "director = LLMRequestDirector(builder)\n",
    "\n",
    "# Construct a full request\n",
    "full_request = director.construct_request(\n",
    "    prompt=\"Tell me a joke.\",\n",
    "    max_tokens=50,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9\n",
    ")\n",
    "print(full_request)\n",
    "\n",
    "# Construct a minimal request\n",
    "minimal_request = director.construct_request(prompt=\"Explain relativity.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': 'Explain relativity.', 'max_tokens': 50, 'temperature': 0.7, 'top_p': 0.9}\n"
     ]
    }
   ],
   "source": [
    "print(minimal_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References:\n",
    "\n",
    "1. https://refactoring.guru/design-patterns/builder\n",
    "\n",
    "2. https://refactoring.guru/design-patterns/builder/python/example#example-0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patterns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
