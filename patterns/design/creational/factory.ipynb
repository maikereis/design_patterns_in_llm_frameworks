{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factory Pattern\n",
    "\n",
    "The Factory Pattern provides an interface for creating objects in a way that abstracts their instantiation logic. This is particularly useful when the creation process is complex or dependent on dynamic parameters.\n",
    "\n",
    "## Use Case 1:\n",
    "\n",
    "In LLM frameworks, you might need to create agents, prompts, or configurations dynamically based on the task or user input.\n",
    "\n",
    "\n",
    "#### Python Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM:\n",
    "    def generate(self, prompt):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class OpenAI(LLM):\n",
    "    def generate(self, prompt):\n",
    "        return f\"OpenAI generating: {prompt}\"\n",
    "\n",
    "class Anthropic(LLM):\n",
    "    def generate(self, prompt):\n",
    "        return f\"Anthropic generating: {prompt}\"\n",
    "\n",
    "class LLMFactory:\n",
    "    @staticmethod\n",
    "    def create_llm(llm_type, **kwargs):\n",
    "        if llm_type == 'openai':\n",
    "            return OpenAI()\n",
    "        elif llm_type == 'anthropic':\n",
    "            return Anthropic()\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown LLM type: {llm_type}\")\n",
    "\n",
    "openai_instance = LLMFactory.create_llm(\"openai\")\n",
    "anthropic_instance = LLMFactory.create_llm(\"anthropic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI generating: Tell me a joke.\n",
      "Anthropic generating: Summarize this text.\n"
     ]
    }
   ],
   "source": [
    "print(openai_instance.generate(\"Tell me a joke.\"))\n",
    "print(anthropic_instance.generate(\"Summarize this text.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case 2\n",
    "\n",
    "Imagine a factory that generates prompts for specific tasks.\n",
    "\n",
    "#### Python Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptFactory:\n",
    "    @staticmethod\n",
    "    def create_prompt(task_type, data):\n",
    "        if task_type == \"summarization\":\n",
    "            return f\"Summarize that following: {data}\"\n",
    "        elif task_type == \"translation\":\n",
    "            return f\"Translate this for French: {data}\"\n",
    "        elif task_type == \"question\":\n",
    "            return f\"Answer this question: {data}\"\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown task type: {task_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize that following: Lorem ipsum dolor sit amet, consectetur adipiscing elit.Etiam eget ligula eu lectus lobortis condimentum. Aliquam nonummy auctor massa. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Nulla at risus. Quisque purus magna, auctor et, sagittis ac, posuere eu, lectus. Nam mattis, felis ut adipiscing.\n",
      "Translate this for French: Hello, how are you?\n",
      "Answer this question: What is Python?\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    PromptFactory.create_prompt(\n",
    "        \"summarization\",\n",
    "        \"\"\"Lorem ipsum dolor sit amet, consectetur adipiscing elit.\\\n",
    "Etiam eget ligula eu lectus lobortis condimentum. Aliquam \\\n",
    "nonummy auctor massa. Pellentesque habitant morbi \\\n",
    "tristique senectus et netus et malesuada fames ac turpis \\\n",
    "egestas. Nulla at risus. Quisque purus magna, auctor et, \\\n",
    "sagittis ac, posuere eu, lectus. Nam mattis, felis ut \\\n",
    "adipiscing.\"\"\",\n",
    "    )\n",
    ")\n",
    "print(PromptFactory.create_prompt(\"translation\", \"Hello, how are you?\"))\n",
    "print(PromptFactory.create_prompt(\"question\", \"What is Python?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References:\n",
    "\n",
    "1. https://refactoring.guru/design-patterns/factory-method\n",
    "\n",
    "2. https://refactoring.guru/design-patterns/factory-method/python/example#example-0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patterns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
