{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decorator Pattern\n",
    "\n",
    "The Decorator Pattern is a structural design pattern used to add new behavior to objects dynamically. Instead of modifying the object directly, the decorator wraps the object and adds additional funcionality while keeping the original interface.\n",
    "\n",
    "## Use Case:\n",
    "\n",
    "In an LLM system, you might want to enhance or extend the functionality of a prompt generation system. For example, addin logging, timing, or post-processing whitout modifying the core logic of the prompt generation.\n",
    "\n",
    "#### Python Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMRequest:\n",
    "    def __init__(self, prompt):\n",
    "        self.prompt = prompt\n",
    "    \n",
    "    def generate_response(self):\n",
    "        return f\"LLM Response: {self.prompt}\"\n",
    "    \n",
    "class LLMRequestDecorator(LLMRequest):\n",
    "    def __init__(self, llm_request):\n",
    "        self.llm_request = llm_request\n",
    "\n",
    "    def generate_response(self):\n",
    "        return self.llm_request.generate_response()\n",
    "    \n",
    "class LoggingDecorator(LLMRequestDecorator):\n",
    "    def generate_response(self):\n",
    "        print(f\"Logging: Generating response for prompt: {self.llm_request.prompt}\")\n",
    "        return self.llm_request.generate_response()\n",
    "    \n",
    "import time\n",
    "class TimingDecorator(LLMRequestDecorator):\n",
    "    def generate_response(self):\n",
    "        start_time = time.time()\n",
    "        response = self.llm_request.generate_response()\n",
    "        end_time = time.time()\n",
    "        print(f\"Timing: Response generated in {end_time - start_time: .2f}\")\n",
    "        return response\n",
    "    \n",
    "llm_request = LLMRequest(\"What is AI?\")\n",
    "\n",
    "logged_request = LoggingDecorator(llm_request)\n",
    "timed_request = TimingDecorator(logged_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging: Generating response for prompt: What is AI?\n",
      "Timing: Response generated in  0.00\n",
      "LLM Response: What is AI?\n"
     ]
    }
   ],
   "source": [
    "print(timed_request.generate_response())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References:\n",
    "\n",
    "1. https://refactoring.guru/design-patterns/decorator\n",
    "\n",
    "2. https://refactoring.guru/design-patterns/decorator/python/example#example-0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patterns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
