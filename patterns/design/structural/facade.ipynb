{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facade Pattern\n",
    "\n",
    "The Facade Pattern is a structural design pattern that provides a simplified interface to a complex subsystem. It hides the complexities of the system and provides a higher-level interface that makes the subsystem easier to use\n",
    "\n",
    "The Facade Pattern is useful in scenarios where there are many components involved in generating a response (e.g., preprocessing, generation, interaction, post-processing). Instead of forcing clients to deal with each component separately, the facade provides a unified interface, abstracting away the internal complexity.\n",
    "\n",
    "## Use Case 1:\n",
    "\n",
    "In an LLM system, you might have multiple components like data processing, prompt generation, model interaction, and post-processing. The Facade Pattern helps by providing a single unified interface to interact with all of these components, making the system easier to use for clients.\n",
    "\n",
    "#### Python Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessing:\n",
    "    def preprocess(self, prompt):\n",
    "        return f\"Preprocessed: {prompt}\"\n",
    "    \n",
    "class PromptGeneration:\n",
    "    def generate(self, prompt):\n",
    "        return f\"Generated prompt: {prompt}\"\n",
    "    \n",
    "class ModelInteraction:\n",
    "    def interact(self, prompt):\n",
    "        return f\"Model response for: {prompt}\"\n",
    "    \n",
    "class PostProcessing:\n",
    "    def postprocess(self, response):\n",
    "        return f\"Postprocessed: {response}\"\n",
    "    \n",
    "class LLMFacade:\n",
    "    def __init__(self):\n",
    "        self.preprocessing = DataPreprocessing()\n",
    "        self.prompt_generation = PromptGeneration()\n",
    "        self.model_interaction = ModelInteraction()\n",
    "        self.post_processing = PostProcessing()\n",
    "\n",
    "    def generate_response(self, raw_prompt):\n",
    "        preprocessed = self.preprocessing.preprocess(raw_prompt)\n",
    "        generated_prompt = self.prompt_generation.generate(preprocessed)\n",
    "        model_response = self.model_interaction.interact(generated_prompt)\n",
    "        return self.post_processing.postprocess(model_response)\n",
    "    \n",
    "facade = LLMFacade()\n",
    "response = facade.generate_response(\"What is the future of AI?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postprocessed: Model response for: Generated prompt: Preprocessed: What is the future of AI?\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case 2:\n",
    "\n",
    "The Facade Pattern can be extended to include more complex workflows. For example, adding support for multiple models, caching, or handling errors gracefully can all be done in the facade.\n",
    "\n",
    "#### Python Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postprocessed: Model response for: Generated prompt: Preprocessed: What is quantum computing?\n",
      "Returning cached response.\n",
      "Postprocessed: Model response for: Generated prompt: Preprocessed: What is quantum computing?\n"
     ]
    }
   ],
   "source": [
    "class Caching:\n",
    "    def __init__(self):\n",
    "        self.cache = {}\n",
    "\n",
    "    def get_from_cache(self, prompt):\n",
    "        return self.cache.get(prompt)\n",
    "    \n",
    "    def save_to_cache(self, prompt, response):\n",
    "        self.cache[prompt] = response\n",
    "\n",
    "class LLMFacadeWithCaching(LLMFacade):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.caching = Caching()\n",
    "\n",
    "    def generate_response(self, raw_prompt):\n",
    "        cached_response = self.caching.get_from_cache(raw_prompt)\n",
    "        if cached_response:\n",
    "            print(\"Returning cached response.\")\n",
    "            return cached_response\n",
    "        else:\n",
    "            response = super().generate_response(raw_prompt)\n",
    "            self.caching.save_to_cache(raw_prompt, response)\n",
    "            return response\n",
    "        \n",
    "facade_with_cache = LLMFacadeWithCaching()\n",
    "response1 = facade_with_cache.generate_response(\"What is quantum computing?\")\n",
    "print(response1)\n",
    "\n",
    "response2 = facade_with_cache.generate_response(\"What is quantum computing?\")\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References:\n",
    "\n",
    "1. https://refactoring.guru/design-patterns/facade\n",
    "\n",
    "2. https://refactoring.guru/design-patterns/facade/python/example#example-0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patterns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
