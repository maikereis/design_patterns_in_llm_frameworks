{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bridge Pattern \n",
    "\n",
    "The Bridge Pattern is a structural design pattern that separates abstraction from implementation. It allows you to change the abstraction and implementation independently without modifying their respective code. This pattern is useful when you have multiple possible variations of both abstractions and implementations.\n",
    "\n",
    "## Use Case 1:\n",
    "\n",
    "In an LLM system, you might have different types of prompt generation (abstractions) and multiple LLM backends (implementations). The Bridge Pattern allows you to decouple the prompt generation logic from the LLM implementation, making it easy to swap out either without affecting the other.\n",
    "\n",
    "#### Python Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMBackend:\n",
    "    def generate_response(self, prompt):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "class OpenAIBackend(LLMBackend):\n",
    "    def generate_response(self, prompt):\n",
    "        return f\"OpenAI generated: {prompt}\"\n",
    "    \n",
    "class AnthropicBackend(LLMBackend):\n",
    "    def generate_response(self, prompt):\n",
    "        return f\"Anthropic generated: {prompt}\"\n",
    "    \n",
    "class PromptGenerator:\n",
    "    def __init__(self, backend: LLMBackend):\n",
    "        self.backend = backend\n",
    "    \n",
    "    def generate(self, prompt):\n",
    "        return self.backend.generate_response(prompt)\n",
    "    \n",
    "\n",
    "class SummarizationPromptGenerator(PromptGenerator):\n",
    "    def generate(self, prompt):\n",
    "        return self.backend.generate_response(f\"Summarize: {prompt}\")\n",
    "    \n",
    "class QuestionAnsweringPromptGenerator(PromptGenerator):\n",
    "    def generate(self, prompt):\n",
    "        return self.backend.generate_response(f\"Anwser this: {prompt}\")\n",
    "    \n",
    "\n",
    "openai_backend = OpenAIBackend()\n",
    "anthropic_backend = AnthropicBackend()\n",
    "\n",
    "summarizer_openai = SummarizationPromptGenerator(openai_backend)\n",
    "qa_anthropic = QuestionAnsweringPromptGenerator(anthropic_backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI generated: Summarize: This is an article about AI.\n",
      "Anthropic generated: Anwser this: What is artificial intelligence?\n"
     ]
    }
   ],
   "source": [
    "print(summarizer_openai.generate(\"This is an article about AI.\"))\n",
    "print(qa_anthropic.generate(\"What is artificial intelligence?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case 2:\n",
    "\n",
    "One of the strengths of the Bridge Pattern is that it allows you to switch betwen backends dynamically without changing the client code.\n",
    "\n",
    "#### Python Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextualPromptGenerator(PromptGenerator):\n",
    "    def generate(self, prompt):\n",
    "        return self.backend.generate_response(f\"Contextualize this: {prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI generated: Contextualize this: AI is transforming industries.\n",
      "Anthropic generated: Contextualize this: AI is transforming industries.\n"
     ]
    }
   ],
   "source": [
    "contextual_prompt = ContextualPromptGenerator(openai_backend)\n",
    "print(contextual_prompt.generate(\"AI is transforming industries.\"))\n",
    "\n",
    "contextual_prompt.backend = anthropic_backend\n",
    "print(contextual_prompt.generate(\"AI is transforming industries.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References:\n",
    "\n",
    "1. https://refactoring.guru/design-patterns/bridge\n",
    "\n",
    "2. https://refactoring.guru/design-patterns/bridge/python/example#example-0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patterns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
